#include <algorithm>
#include <float.h>
#include <iostream>
#include <torch/extension.h>
#include <torch/types.h>
#include <ATen/xpu/XPUContext.h>
#include <vector>
#include <cutlass/gemm/device/gemm_universal_adapter.h>
#include "cutlass/util/packed_stride.hpp"
#include "flash_attention_v2/collective/fmha_fusion.hpp"
#include "flash_attention_v2/kernel/xe_fhma_fwd_kernel.hpp"
#include "flash_attention_v2/kernel/xe_tile_scheduler.hpp"
#include "cutlass/epilogue/collective/default_epilogue.hpp"
#include <cute/tensor.hpp>
#include "cutlass/kernel_hardware_info.h"
#include "cutlass/platform/platform.h"
#include "cutlass/tensor_ref.h"
#include "cutlass/util/sycl_event_manager.hpp"
#include "cutlass/util/GPU_Clock.hpp"
#include "cutlass/util/reference/device/gemm_complex.h"
#include "cutlass/util/reference/device/tensor_compare.h"
#include "cutlass/util/reference/host/tensor_fill.h"
#include "cutlass/fast_math.h"
#include <cutlass/gemm/threadblock/threadblock_swizzle.h>
#include <cute/util/compat.hpp>

#include <sycl/sycl.hpp>

#include <sycl/ext/intel/experimental/grf_size_properties.hpp>

#pragma clang diagnostic ignored "-Wdeprecated-declarations"

using namespace cute;
using LayoutQ = cutlass::layout::RowMajor;
using LayoutK = cutlass::layout::ColumnMajor;
using LayoutV = cutlass::layout::RowMajor;
using LayoutO = cutlass::layout::RowMajor;

template <class kernel>
class xe_fmha_kernel;

template <bool Causal,
          typename TileShapeQK,
          typename TileShapePV,
          typename TileShapeOutput,
          typename SubgroupLayoutQK,
          typename SubgroupLayoutPV_, /* void -> default */
          int PipelineStages,
          bool persistent,
          typename ElementQ = half_t,
          typename ElementK = half_t,
          typename ElementV = half_t,
          typename ElementO = half_t,
          typename MMAOperation_ = void, /* void -> default */
          typename StrideQ = Stride<int, _1, int, int>,
          typename StrideK = Stride<int, _1, int, int>,
          typename StrideV = Stride<_1, int, int, int>,
          typename StrideO = Stride<int, _1, int, int>,
          typename GmemTiledCopyQ = void, /* void -> default block 2D */
          typename GmemTiledCopyK = void,
          typename GmemTiledCopyV = void,
          typename GmemTiledCopyO = void>
cutlass::Status cute_example_mha(
    cute::half_t const *q,
    cute::half_t const *k,
    cute::half_t const *v,
    cute::half_t *out,
    const int batch_size,
    const int seqlen_q,
    const int num_head,
    const int head_dim,
    const int seqlen_k,
    torch::Device device)
{
  auto queue = at::xpu::getCurrentXPUStream().queue();
  // block_m / subgroup_m = 128 / 16 = 8
  static constexpr int SGTileQ = get<0>(shape_div(TileShapeQK{}, shape(SubgroupLayoutQK{})))();
  using MMAOperation = cute::conditional_t<is_void_v<MMAOperation_>,
                                           typename cute::conditional_t<
                                               cute::is_same_v<ElementQ, cutlass::float_e5m2_t> || cute::is_same_v<ElementQ, cutlass::float_e4m3_t>,
                                               XE_DPAS_TT<cute::gcd(SGTileQ, 8), float, half_t>,
                                               XE_DPAS_TT<cute::gcd(SGTileQ, 8), float, ElementQ>>,
                                           MMAOperation_>;
  using SubgroupLayoutPV = cute::conditional_t<is_void_v<SubgroupLayoutPV_>,
                                               decltype(cutlass::fmha::collective::get_sg_layout_pv(SubgroupLayoutQK{})),
                                               SubgroupLayoutPV_>;
  // SubgroupLayoutPV (_16,_1,_1)

  using Scheduler = cute::conditional_t<persistent,
                                        cutlass::fmha::kernel::XeFHMAIndividualPersistentTileScheduler,
                                        cutlass::fmha::kernel::XeFHMAIndividualTileScheduler>;
  // The KernelHardwareInfo struct holds the number of EUs on the GPU with a given device ID. This
  // information is used by the underlying kernel.
  cutlass::KernelHardwareInfo hw_info;
  hw_info.sm_count = cutlass::KernelHardwareInfo::query_device_multiprocessor_count(hw_info.device_id);

  using ProblemShapeType = cutlass::fmha::kernel::FMHAProblemShape<false>;

  using TiledMMAQK = typename TiledMMAHelper<MMA_Atom<MMAOperation>, Layout<TileShapeQK>, SubgroupLayoutQK>::TiledMMA;
  // TiledMMA
  //   ThrLayoutVMNK:  (_16,_16,_1,_1):(_1,_16,_0,_0)
  //   PermutationMNK: (_128:_1,_64:_1,_32:_1)
  // MMA_Atom
  //   ThrID:      _16:_1
  //   Shape_MNK:  (_8,_16,_16)
  //   LayoutA_TV: (_16,_8):(_8,_1)
  //   LayoutB_TV: ((_2,_8),(_2,_8)):((_16,_1),(_8,_32))
  //   LayoutC_TV: (_16,_8):(_8,_1)

  using TiledMMAPV = typename TiledMMAHelper<MMA_Atom<MMAOperation>, Layout<TileShapePV>, SubgroupLayoutPV>::TiledMMA;
  // TiledMMA
  //   ThrLayoutVMNK:  (_16,_16,_1,_1):(_1,_16,_0,_0)
  //   PermutationMNK: (_128:_1,_32:_1,_64:_1)
  // MMA_Atom
  //   ThrID:      _16:_1
  //   Shape_MNK:  (_8,_16,_16)
  //   LayoutA_TV: (_16,_8):(_8,_1)
  //   LayoutB_TV: ((_2,_8),(_2,_8)):((_16,_1),(_8,_32))
  //   LayoutC_TV: (_16,_8):(_8,_1)

  static_assert(get<0>(TileShapeOutput{}) == get<0>(TileShapePV{}),
                "Output tile and P*V tile have different sizes in Q dimension");
  constexpr int VTiles = get<1>(TileShapeOutput{}) / get<1>(TileShapePV{}); // 128 / 32 = 4
  auto make_dummy_tensor = [&](auto val, auto stride)
  {
    return make_tensor(make_gmem_ptr(&val),
                       make_layout(repeat<rank_v<decltype(stride)>>(1), stride));
  };

  using TensorQ = decltype(make_dummy_tensor(ElementQ{}, StrideQ{}));
  using TensorK = decltype(make_dummy_tensor(ElementK{}, StrideK{}));
  using TensorV = decltype(make_dummy_tensor(ElementV{}, StrideV{}));
  using TensorO = decltype(make_dummy_tensor(ElementO{}, StrideO{}));

  // Mainloop
  using MainloopDispatchPolicy = cutlass::fmha::XeDefault<PipelineStages>;
  using CollectiveMainloop = cutlass::fmha::collective::FMHAFwdMainloop<
      MainloopDispatchPolicy, Causal,
      TiledMMAQK, TiledMMAPV, VTiles,
      TensorQ, TensorK, TensorV,
      GmemTiledCopyQ, GmemTiledCopyK, GmemTiledCopyV>;

  // Epilogue
  using CollectiveEpilogue = cutlass::fmha::collective::FMHAFwdEpilogue<
      CollectiveMainloop,
      TileShapeOutput,
      TensorO,
      GmemTiledCopyO>;

  using FMHAKernel = conditional_t<is_same_v<Scheduler, cutlass::fmha::kernel::XeFHMAIndividualPersistentTileScheduler>,
                                   cutlass::fmha::kernel::XeFMHAFwdDynamicSplitKernel<
                                       ProblemShapeType, CollectiveMainloop, CollectiveEpilogue, Scheduler>,
                                   cutlass::fmha::kernel::XeFMHAFwdKernel<
                                       ProblemShapeType, CollectiveMainloop, CollectiveEpilogue, Scheduler>>;

  using ElementS = typename FMHAKernel::CollectiveMainloop::ElementS;

  ProblemShapeType shape;
  shape.batch = batch_size;
  shape.num_heads_q = num_head;
  shape.num_heads_kv = num_head;
  shape.seq_len_qo = seqlen_q;
  shape.seq_len_kv = seqlen_k;
  shape.head_size_qk = head_dim;
  shape.head_size_vo = head_dim;
  StrideQ stride_Q = cutlass::make_cute_packed_stride(StrideQ{}, cute::make_shape(shape.seq_len_qo, shape.head_size_qk, shape.num_heads_q, shape.batch));
  StrideK stride_K = cutlass::make_cute_packed_stride(StrideK{}, cute::make_shape(shape.seq_len_kv, shape.head_size_qk, shape.num_heads_kv, shape.batch));
  StrideV stride_V = cutlass::make_cute_packed_stride(StrideV{}, cute::make_shape(shape.head_size_vo, shape.seq_len_kv, shape.num_heads_kv, shape.batch));
  StrideO stride_O = cutlass::make_cute_packed_stride(StrideO{}, cute::make_shape(shape.seq_len_qo, shape.head_size_vo, shape.num_heads_q, shape.batch));
  // equivalent to contiguous (batch, num_heads, seqlen_q, head_dim)
  typename FMHAKernel::Arguments arguments{
      {shape,
       q, stride_Q, k, stride_K, v, stride_V, out, stride_O},
      {1 / sqrt(static_cast<float>(shape.head_size_qk))},
      {},
      hw_info};


  size_t workspace_size = FMHAKernel::get_workspace_size(arguments);
  auto workspace = torch::empty({static_cast<int64_t>(workspace_size)}, torch::dtype(torch::kUInt8).device(device));

  if (!FMHAKernel::can_implement(arguments))
  {
    std::cout << "Invalid Problem Size: " << shape.batch << 'x' << shape.num_heads_q << 'x' << shape.seq_len_qo << 'x' << shape.seq_len_kv << 'x' << shape.head_size_qk << 'x' << shape.head_size_vo
              << (Causal ? "xCausal" : "xNonCausal") << std::endl;
    return cutlass::Status::kErrorInvalidProblem;
  }

  // Initialize the workspace
  FMHAKernel::initialize_workspace(arguments, workspace.data_ptr<uint8_t>());

  // Convert host-side arguments to device-side arguments to be passed to the kernel
  auto params = FMHAKernel::to_underlying_arguments(arguments, workspace.data_ptr<uint8_t>());

  // Run the GEMM
  dim3 const block = FMHAKernel::get_block_shape();
  dim3 const grid = FMHAKernel::get_grid_shape(params);

  // configure smem size and carveout
  int smem_size = FMHAKernel::SharedStorageSize;
  // 0

  const auto sycl_block = compat::dim3(block.x, block.y, block.z);
  // grid.x = head_size_vo / head_dim = 1
  // grid.y = seqlen_q / m_block_size
  // grid.z = batch_size * num_head
  // block.x = 256
  // block.y = 1
  // block.z = 1
  const auto sycl_grid = compat::dim3(grid.x, grid.y, grid.z);

  compat::experimental::launch_properties launch_props{
      sycl::ext::oneapi::experimental::work_group_scratch_size(smem_size),
  };
  compat::experimental::kernel_properties kernel_props{
      sycl::ext::oneapi::experimental::sub_group_size<cute::intel::sg_size>, sycl::ext::intel::experimental::grf_size<256>};
  compat::experimental::launch_policy policy{sycl_grid, sycl_block, launch_props, kernel_props};
  auto event = compat::experimental::launch<cutlass::device_kernel<FMHAKernel>, xe_fmha_kernel<FMHAKernel>>(policy, queue, params);

  return cutlass::Status::kSuccess;
}

void cute_example_xe(torch::Tensor &q, torch::Tensor &k, torch::Tensor &v, torch::Tensor &out)
{
  const int batch_size = q.size(0);
  const int seqlen_q = q.size(2);
  const int num_head = q.size(1);
  const int head_dim = q.size(3);
  const int seqlen_k = k.size(2);
  constexpr int PipelineStages = 2;
  cutlass::Status result;

  // ShapeOut (m_block, head_dim)
  if (head_dim == 64)
  {
    using ShapeQK = Shape<_128, _64, _32>;
    using ShapePV = Shape<_128, _32, _64>;
    using ShapeOut = Shape<_128, _64>;
    using SubgroupLayoutQK = Layout<Shape<_8, _1, _1>>;
    result = cute_example_mha</*causal*/ false, ShapeQK, ShapePV, ShapeOut, SubgroupLayoutQK, void, PipelineStages, /*persistent=*/false, cute::half_t, cute::half_t, cute::half_t>(reinterpret_cast<cute::half_t *>(q.data_ptr()),
                                                                                                                                                                                    reinterpret_cast<cute::half_t *>(k.data_ptr()),
                                                                                                                                                                                    reinterpret_cast<cute::half_t *>(v.data_ptr()),
                                                                                                                                                                                    reinterpret_cast<cute::half_t *>(out.data_ptr()),
                                                                                                                                                                                    batch_size,
                                                                                                                                                                                    seqlen_q,
                                                                                                                                                                                    num_head,
                                                                                                                                                                                    head_dim,
                                                                                                                                                                                    seqlen_k,
                                                                                                                                                                                    q.device());
  }
  else if (head_dim == 96)
  {
    using ShapeQK = Shape<_128, _64, _32>;
    using ShapePV = Shape<_128, _32, _64>;
    using ShapeOut = Shape<_128, _96>;
    using SubgroupLayoutQK = Layout<Shape<_8, _1, _1>>;
    result = cute_example_mha</*causal*/ false, ShapeQK, ShapePV, ShapeOut, SubgroupLayoutQK, void, PipelineStages, /*persistent=*/false, cute::half_t, cute::half_t, cute::half_t>(reinterpret_cast<cute::half_t *>(q.data_ptr()),
                                                                                                                                                                                    reinterpret_cast<cute::half_t *>(k.data_ptr()),
                                                                                                                                                                                    reinterpret_cast<cute::half_t *>(v.data_ptr()),
                                                                                                                                                                                    reinterpret_cast<cute::half_t *>(out.data_ptr()),
                                                                                                                                                                                    batch_size,
                                                                                                                                                                                    seqlen_q,
                                                                                                                                                                                    num_head,
                                                                                                                                                                                    head_dim,
                                                                                                                                                                                    seqlen_k,
                                                                                                                                                                                    q.device());
  }
  else if (head_dim == 128)
  {
    using ShapeQK = Shape<_128, _64, _32>;
    using ShapePV = Shape<_128, _32, _64>;
    using ShapeOut = Shape<_128, _128>;
    using SubgroupLayoutQK = Layout<Shape<_16, _1, _1>>; // 16 subgroups on m
    result = cute_example_mha</*causal*/ false, ShapeQK, ShapePV, ShapeOut, SubgroupLayoutQK, void, PipelineStages, /*persistent=*/false, cute::half_t, cute::half_t, cute::half_t>(reinterpret_cast<cute::half_t *>(q.data_ptr()),
                                                                                                                                                                                    reinterpret_cast<cute::half_t *>(k.data_ptr()),
                                                                                                                                                                                    reinterpret_cast<cute::half_t *>(v.data_ptr()),
                                                                                                                                                                                    reinterpret_cast<cute::half_t *>(out.data_ptr()),
                                                                                                                                                                                    batch_size,
                                                                                                                                                                                    seqlen_q,
                                                                                                                                                                                    num_head,
                                                                                                                                                                                    head_dim,
                                                                                                                                                                                    seqlen_k,
                                                                                                                                                                                    q.device());
  }
  else if (head_dim == 192) 
  {
    using ShapeQK = Shape<_256, _64, _32>;
    using ShapePV = Shape<_256, _32, _64>;
    using ShapeOut = Shape<_256, _192>;
    using SubgroupLayoutQK = Layout<Shape<_32, _1, _1>>;
    result = cute_example_mha</*causal*/ false, ShapeQK, ShapePV, ShapeOut, SubgroupLayoutQK, void, PipelineStages, /*persistent=*/false, cute::half_t, cute::half_t, cute::half_t>(reinterpret_cast<cute::half_t *>(q.data_ptr()),
                                                                                                                                                                                    reinterpret_cast<cute::half_t *>(k.data_ptr()),
                                                                                                                                                                                    reinterpret_cast<cute::half_t *>(v.data_ptr()),
                                                                                                                                                                                    reinterpret_cast<cute::half_t *>(out.data_ptr()),
                                                                                                                                                                                    batch_size,
                                                                                                                                                                                    seqlen_q,
                                                                                                                                                                                    num_head,
                                                                                                                                                                                    head_dim,
                                                                                                                                                                                    seqlen_k,
                                                                                                                                                                                    q.device());
  }
  else
  {
    std::cerr << "Unsupported head_dim: " << head_dim << std::endl;
    return;
  }
  if (result != cutlass::Status::kSuccess)
  {
    std::cerr << "CUTLASS mha kernel failed: "
              << cutlassGetStatusString(result) << std::endl;
  }
}
