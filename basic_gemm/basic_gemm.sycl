#include <torch/extension.h> // include it first, otherwise compile error because
/*cutlass-sycl/include/cute/util/print.hpp:38:20: note: expanded from macro 'printf'
   38 | #define printf sycl::ext::oneapi::experimental::printf
*/
#include <torch/types.h>

#include <cutlass/cutlass.h>
#include <cutlass/epilogue/collective/default_epilogue.hpp>
#include <cutlass/epilogue/collective/xe_epilogue.hpp>
#include <cutlass/epilogue/fusion/xe_callbacks.hpp>
#include <cutlass/gemm/device/gemm_universal.h>
#include <cutlass/gemm/device/gemm_universal_adapter.h>
#include <cutlass/gemm/collective/collective_mma.hpp>
#include <cutlass/util/GPU_Clock.hpp>

#include <cutlass/util/packed_stride.hpp>
#include <cutlass/kernel_hardware_info.h>

#include <cute/tensor.hpp>
#include <random>

using namespace cute;

cutlass::Status basic_cutlass_gemm(
    int M,
    int N,
    int K,
    float alpha,
    cutlass::half_t const *A,
    int lda,
    cutlass::half_t const *B,
    int ldb,
    float beta,
    cutlass::half_t *C,
    int ldc,
    torch::Device device)
{

  using RowMajor = cutlass::layout::RowMajor;
  using ColumnMajor = cutlass::layout::ColumnMajor;

  using ElementA = cutlass::half_t;
  using ElementB = cutlass::half_t;
  using ElementC = cutlass::half_t;
  using ElementD = cutlass::half_t;
  using ElementAccumulator = float;
  using ElementComputeEpilogue = float;
  using ElementScalar = float;

  using LayoutA = RowMajor;
  using LayoutB = RowMajor;
  using LayoutC = RowMajor;
  using LayoutD = RowMajor;

  using GmemTiledCopyA = XE_2D_U16x32x32_LD_N;
  using GmemTiledCopyB = XE_2D_U16x32x32_LD_V;

  // Workgroup-level tile
  using TileShape = Shape<_256, _256, _32>;

  // The Tile of this layout describes how 8x4x1 sub-groups tile the TileShape of <256, 256, 32>.
  // This permutation (which can be thought of as a scatter operation on the default tiling)
  // ensures that each sub-group operates on a contiguous 32x64x32 chunk (4x4x2 iterations)
  // See 0t_mma_atom.md#TiledMMAs for more info.
  // Sub-groups are arranged row-major (stride 4,1,0) for performance reasons.
  using TiledMma =
      typename TiledMMAHelper<MMA_Atom<XE_8x16x16_F32F16F16F32_TT>, Layout<TileShape>,
                              Layout<Shape<_8, _4, _1>, Stride<_4, _1, _0>>>::TiledMMA;
  constexpr int PipelineStages = 2;
  using GEMMDispatchPolicy = cutlass::gemm::MainloopIntelXeXMX16<PipelineStages>;
  using EpilogueDispatchPolicy = cutlass::epilogue::IntelXeXMX16;
  using EpilogueOp = cutlass::epilogue::fusion::LinearCombination<ElementD, ElementComputeEpilogue,
                                                                  ElementAccumulator, ElementAccumulator, cutlass::FloatRoundStyle::round_to_nearest>;

  using FusionCallBacks = cutlass::epilogue::fusion::FusionCallbacks<EpilogueDispatchPolicy, EpilogueOp, TileShape,
                                                                     decltype(tile_shape(TiledMma()))>;
  using CollectiveEpilogue = cutlass::epilogue::collective::CollectiveEpilogue<
      EpilogueDispatchPolicy,
      TileShape,
      ElementAccumulator,
      cutlass::gemm::TagToStrideC_t<LayoutC>,
      ElementD,
      cutlass::gemm::TagToStrideC_t<LayoutD>,
      FusionCallBacks,
      XE_2D_U32x8x16_LD_N,
      void, void,
      XE_2D_U32x8x16_ST_N,
      void, void>;
  // Mainloop
  using CollectiveMainloop = cutlass::gemm::collective::CollectiveMma<
      GEMMDispatchPolicy,
      TileShape,
      ElementA,
      cutlass::gemm::TagToStrideA_t<LayoutA>,
      ElementB,
      cutlass::gemm::TagToStrideB_t<LayoutB>,
      TiledMma,
      GmemTiledCopyA, void, void, cute::identity, // A
      GmemTiledCopyB, void, void, cute::identity  // B
      >;
  using GemmKernel = cutlass::gemm::kernel::GemmUniversal<
      Shape<int, int, int, int>,
      CollectiveMainloop,
      CollectiveEpilogue>;

  using Gemm = cutlass::gemm::device::GemmUniversalAdapter<GemmKernel>;
  /*using ProblemShapeType = typename Gemm::GemmKernel::ProblemShape;

  // The KernelHardwareInfo struct holds the number of EUs on the GPU with a given device ID. This
  // information is used by the underlying kernel.
  cutlass::KernelHardwareInfo hw_info;

  // Change device_id to another value if you are running on a machine with multiple GPUs and wish
  // to use a GPU other than that with device ID 0.
  hw_info.sm_count = cutlass::KernelHardwareInfo::query_device_multiprocessor_count(hw_info.device_id);

  using StrideA = typename Gemm::GemmKernel::StrideA;
  using StrideB = typename Gemm::GemmKernel::StrideB;
  using StrideC = typename Gemm::GemmKernel::StrideC;
  using StrideD = typename Gemm::GemmKernel::StrideD;

  StrideA stride_A = cutlass::make_cute_packed_stride(StrideA{}, cute::make_shape(M, K, 1));
  StrideB  stride_B = cutlass::make_cute_packed_stride(StrideB{}, cute::make_shape(N, K, 1));
  StrideC  stride_C = cutlass::make_cute_packed_stride(StrideC{}, cute::make_shape(M, N, 1));
  StrideD  stride_D = cutlass::make_cute_packed_stride(StrideD{}, cute::make_shape(M, N, 1));

  typename Gemm::GemmKernel::Arguments arguments{
      cutlass::gemm::GemmUniversalMode::kGemm,
      {M, N, K, 1}, // l = batch size = 1
      {A, stride_A, B, stride_B},
      {{alpha, beta}, C, stride_C, C, stride_D},
      hw_info
    };

  Gemm gemm_op;
  //
  // Launch the CUTLASS GEMM kernel.
  //
  // workspace_size should be 0 becuase split_k_slices = 1, we can also directly call gemm_operator(args)
  size_t workspace_size = CutlassGemm::get_workspace_size(arguments);
  auto workspace = torch::empty({static_cast<int64_t>(workspace_size)}, torch::dtype(torch::kUInt8).device(device));
  gemm_operator.initialize(arguments, workspace.data_ptr<uint8_t>());
  cutlass::Status status = gemm_operator();
  // cutlass::Status status = gemm_operator(args);

  if (status != cutlass::Status::kSuccess)
  {
    cutlass::Status error = status;
    std::cerr << "Got cutlass error: " << cutlassGetStatusString(error) << std::endl;
    return cutlass::Status::kErrorInternal;
  }*/

  // Return success, if no errors were encountered.
  return cutlass::Status::kSuccess;
}

#define STRINGFY(str) #str
#define TORCH_BINDING_COMMON_EXTENSION(func) \
  m.def(STRINGFY(func), &func, STRINGFY(func));

void basic_gemm(torch::Tensor &a, torch::Tensor &b, torch::Tensor &c)
{
  const int M = a.size(0);
  const int K = a.size(1);
  const int N = b.size(1);
  const int lda = K;
  const int ldb = K;
  const int ldc = N;
  auto result = basic_cutlass_gemm(M, N, K, 1., reinterpret_cast<cutlass::half_t *>(a.data_ptr()), lda, reinterpret_cast<cutlass::half_t *>(b.data_ptr()), ldb, 0., reinterpret_cast<cutlass::half_t *>(c.data_ptr()), ldc, a.device());
  if (result != cutlass::Status::kSuccess)
  {
    std::cerr << "CUTLASS GEMM kernel failed: "
              << cutlassGetStatusString(result) << std::endl;
  }
}

extern void cute_example(torch::Tensor &a, torch::Tensor &b, torch::Tensor &c);

PYBIND11_MODULE(TORCH_EXTENSION_NAME, m)
{
  TORCH_BINDING_COMMON_EXTENSION(basic_gemm);
  TORCH_BINDING_COMMON_EXTENSION(cute_example);
}
